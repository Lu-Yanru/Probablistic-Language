//Parameter estimation
// estimate which modal (L0 litListener or L1 pragmaListener with alpha = 1) suits the data better

var total_observations = 180
var observed_successes = 115
var LH_literalLister = Math.exp(Binomial({n: total_observations,
                                          p: 0.5}).score(observed_successes)) //p: probabiliy of success, score function: log probability of all observed successes // literal listener correctly infering the referent
var LH_pragmatLister = Math.exp(Binomial({n: total_observations,
                                          p: 0.6}).score(observed_successes))
var posterior_literalListener = LH_literalLister /  //the probability P(M∣D) of the literal listener model given the data
    (LH_literalLister + LH_pragmatLister)
display(posterior_literalListener)

var posterior_pragmaticListener = LH_pragmatLister /  //the probability P(M∣D) of the pragmatic listener model given the data
    (LH_literalLister + LH_pragmatLister)
display(posterior_pragmaticListener)

// more observed success, more likely is pragmatic listener. Less observed successes, more likely is literal listener.
// With successes/total around 0.5, literal listener modal more likely, successes/total rate around 0.6, pragmatic listener  modal more likely, in between uncertainty.
// As num of total observations goes up (proportion of observed successes remains the same), pragmaListener even more likely. -> addding more data gives us more certainty about models, intermediate range becomes sharper
// Bay's factor: probability of pragmaListener/probability of litListener, fairly confident about a better modal if >= 10.




// estimate the value of alpha

// Frank and Goodman (2012) RSA model

///fold:

// set of states (here: objects of reference)
var states = ["blue_circle", "green_square", "blue_square"]

// set of utterances
var utterances = ["blue","green","square","circle"]

// prior over world states
var objectPrior = function() {
  uniformDraw(states)
}

// meaning function to interpret the utterances
var meaning = function(utterance, obj){
  _.includes(obj, utterance)
}

// literal listener
var literalListener = function(utterance){
  Infer({model: function(){
    var obj = objectPrior();
    condition(meaning(utterance, obj))
    return obj
  }})
}

// pragmatic speaker
var speaker = function(obj, alpha){ //alpha is now an argument
  Infer({model: function(){
    var utterance = uniformDraw(utterances)
    factor(alpha * literalListener(utterance).score(obj))
    return utterance
  }})
}

// pragmatic listener
var pragmaticListener = function(utterance, alpha){ //alpha is now an argument
  Infer({model: function(){
    var obj = objectPrior()
    observe(speaker(obj, alpha),utterance) // pass alpha to the speaker function
    return obj
  }})
}

///

// Data analysis

var non_normalized_posterior = function(){
  // prior over model parameter
  var alpha = uniform({a:0, b:10}) // sampling alpha uniformly from the range 0 to 10
  var predicted_probability =
      Math.exp(
        pragmaticListener("blue", alpha).score("blue_square")
      )
  var likelihood = Binomial({n: 180, p: predicted_probability}).score(115)   // score function: probability that the number of successes if assume alpha = sample is going to be 115 
  factor(likelihood)
  return {alpha} // distribution of alpha by taking the observed data under differente alpha sampled
}

var posterior_samples = Infer({
  method: "MCMC", // a way of computing Bayesian by sampling from distributions
  samples: 10000, // how many samples to obtain
  burn: 1500,     // number of steps for algorithm to adapt
  model: non_normalized_posterior})

viz(posterior_samples)
// result: peak at around 1.3
// interpretation: not completely irrational

// if increase the amount of data: data shift less from the uniform to gamma prior (the more data the less the prior matters), because there is less uncertainty (less reliance on what we already know)






// Full example
var salience_priors = { //"Which could the speaker possibly be talking about?"
  blue_circle:   71,  // object "blue circle" was selected 71 times
  green_square: 139,  // diff color makes the object salient -> most likely to be selected
  blue_square:   30,
}

var prod_data = {
  blue_circle:  {blue:  9, circle: 135, green:   0, square:  0},
  green_square: {blue:  0, circle:   0, green: 119, square: 25}, // asymmetric preference, bias for producing a shape term compared to a color term -> shapes are nouns and color are adj, usu use nouns to refer to adj, color term may be more costly than shape terms in this experiment? 
  blue_square:  {blue: 63, circle:   0, green:   0, square: 81}
}

var comp_data = {
  blue:   {blue_circle: 65, green_square:   0, blue_square: 115},
  square: {blue_circle:  0, green_square: 117, blue_square:  62}
}

// put salience prior into object prior
// prior over world states
var objectPrior = function() {
  categorical({ps: _.values(salience_priors), // empirical data
               vs: _.keys(salience_priors)}) // diff objects
}

Infer({model: objectPrior})

// Diff cost for shape and color
// function for utterance costs
var cost = function(utterance, c) {
  (utterance === "blue" || utterance === "green") ? c : 0
}

// pragmatic speaker
var speaker = function(obj, alpha, c){
  Infer({model: function(){
    var utterance = uniformDraw(utterances)
    factor(alpha * (literalListener(utterance).score(obj) -
                    cost(utterance,c)))
    return utterance
  }})
}

// pragmatic listener also receives cost term 'c'
// pragmatic listener
var pragmaticListener = function(utterance, alpha, c){
  Infer({model: function(){
    var obj = objectPrior()
    observe(speaker(obj, alpha, c),utterance)
    return obj
  }})
}

// model parameters
var alpha = 1
var c = 0 // if increase cost of color terms, speaker less likely to use the term, pragmatic listener take into account that speaker 

// display full probability tables

display("literal listener")
display(condProb2Table(literalListener, utterances, states,2))

display("speaker")
display(condProb2Table(function(s) {speaker(s,alpha,c)}, states, utterances,2))

display("pragmatic listener")
display(condProb2Table(function(u) {pragmaticListener(u,alpha,c)}, utterances, states,2))

